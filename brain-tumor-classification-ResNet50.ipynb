{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b>1 <span style='color:#4285f4'>|</span> Importing libraries</b>\n- **For ML Models**: Tensorflow, keras\n- **For Data Manipulation**: numpy, pandas, sklearn\n- **For Data Visualization**: matplotlib, seaborn","metadata":{}},{"cell_type":"code","source":"# For Data Processing\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom PIL import Image, ImageEnhance\n\n# For ML Models\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import load_img\n\n# For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Miscellaneous\nfrom tqdm import tqdm\nimport os\nimport random","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-09T21:14:04.691014Z","iopub.execute_input":"2023-06-09T21:14:04.691722Z","iopub.status.idle":"2023-06-09T21:14:12.477175Z","shell.execute_reply.started":"2023-06-09T21:14:04.691609Z","shell.execute_reply":"2023-06-09T21:14:12.476190Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# <b>2 <span style='color:#4285f4'>|</span> Reading the Dataset</b>","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training/'\ntest_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing/'\n\ntrain_paths = []\ntrain_labels = []\n\nfor label in os.listdir(train_dir):\n    for image in os.listdir(train_dir+label):\n        train_paths.append(train_dir+label+'/'+image)\n        train_labels.append(label)\n\ntrain_paths, train_labels = shuffle(train_paths, train_labels)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:01.147997Z","iopub.execute_input":"2022-04-17T19:25:01.148483Z","iopub.status.idle":"2022-04-17T19:25:01.173028Z","shell.execute_reply.started":"2022-04-17T19:25:01.148452Z","shell.execute_reply":"2022-04-17T19:25:01.172038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\ncolors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\nplt.rcParams.update({'font.size': 14})\nplt.pie([len([x for x in train_labels if x=='pituitary']),\n         len([x for x in train_labels if x=='notumor']),\n         len([x for x in train_labels if x=='meningioma']),\n         len([x for x in train_labels if x=='glioma'])],\n        labels=['pituitary','notumor', 'meningioma', 'glioma'],\n        colors=colors, autopct='%.1f%%', explode=(0.025,0.025,0.025,0.025),\n        startangle=30);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:02.738484Z","iopub.execute_input":"2022-04-17T19:25:02.745344Z","iopub.status.idle":"2022-04-17T19:25:03.117356Z","shell.execute_reply.started":"2022-04-17T19:25:02.745286Z","shell.execute_reply":"2022-04-17T19:25:03.116389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The dataset is reasonably balanced","metadata":{}},{"cell_type":"code","source":"test_paths = []\ntest_labels = []\n\nfor label in os.listdir(test_dir):\n    for image in os.listdir(test_dir+label):\n        test_paths.append(test_dir+label+'/'+image)\n        test_labels.append(label)\n\ntest_paths, test_labels = shuffle(test_paths, test_labels)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:05.813987Z","iopub.execute_input":"2022-04-17T19:25:05.814771Z","iopub.status.idle":"2022-04-17T19:25:05.829695Z","shell.execute_reply.started":"2022-04-17T19:25:05.814739Z","shell.execute_reply":"2022-04-17T19:25:05.828394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\ncolors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\nplt.rcParams.update({'font.size': 14})\nplt.pie([len(train_labels), len(test_labels)],\n        labels=['Train','Test'],\n        colors=colors, autopct='%.1f%%', explode=(0.05,0),\n        startangle=30);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:09.546186Z","iopub.execute_input":"2022-04-17T19:25:09.54651Z","iopub.status.idle":"2022-04-17T19:25:09.661104Z","shell.execute_reply.started":"2022-04-17T19:25:09.546465Z","shell.execute_reply":"2022-04-17T19:25:09.659834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>3 <span style='color:#4285f4'>|</span> Data Augmentation</b>\n- Random Brightness: 80% - 120%  \n- Random Contrast: 80% - 120%\n","metadata":{}},{"cell_type":"code","source":"def augment_image(image):\n    image = Image.fromarray(np.uint8(image))\n    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8,1.2))\n    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8,1.2))\n    image = np.array(image)/255.0\n    return image","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:12.006271Z","iopub.execute_input":"2022-04-17T19:25:12.00657Z","iopub.status.idle":"2022-04-17T19:25:12.012862Z","shell.execute_reply.started":"2022-04-17T19:25:12.00654Z","shell.execute_reply":"2022-04-17T19:25:12.011579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family:Sans;\">Let's plot some Samples :</h3>","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 128\n\ndef open_images(paths):\n    '''\n    Given a list of paths to images, this function returns the images as arrays (after augmenting them)\n    '''\n    images = []\n    for path in paths:\n        image = load_img(path, target_size=(IMAGE_SIZE,IMAGE_SIZE))\n        image = augment_image(image)\n        images.append(image)\n    return np.array(images)\n\nimages = open_images(train_paths[50:59])\nlabels = train_labels[50:59]\nfig = plt.figure(figsize=(12, 6))\nfor x in range(1, 9):\n    fig.add_subplot(2, 4, x)\n    plt.axis('off')\n    plt.title(labels[x])\n    plt.imshow(images[x])\nplt.rcParams.update({'font.size': 12})\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:14.278846Z","iopub.execute_input":"2022-04-17T19:25:14.27919Z","iopub.status.idle":"2022-04-17T19:25:14.861767Z","shell.execute_reply.started":"2022-04-17T19:25:14.279117Z","shell.execute_reply":"2022-04-17T19:25:14.858831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>4 <span style='color:#4285f4'>|</span> Data Generator</b>\n<p style=\"font-size:15px; font-family:Sans; line-height: 1.7em\">\n    Given a list of paths to images, and the labels, <br>\n    this function augments the images, normalizes them, encodes the label, and then returns the batch on which the model can train on. <br>\n</p>","metadata":{}},{"cell_type":"code","source":"unique_labels = os.listdir(train_dir)\n\ndef encode_label(labels):\n    encoded = []\n    for x in labels:\n        encoded.append(unique_labels.index(x))\n    return np.array(encoded)\n\ndef decode_label(labels):\n    decoded = []\n    for x in labels:\n        decoded.append(unique_labels[x])\n    return np.array(decoded)\n\ndef datagen(paths, labels, batch_size=12, epochs=1):\n    for _ in range(epochs):\n        for x in range(0, len(paths), batch_size):\n            batch_paths = paths[x:x+batch_size]\n            batch_images = open_images(batch_paths)\n            batch_labels = labels[x:x+batch_size]\n            batch_labels = encode_label(batch_labels)\n            yield batch_images, batch_labels","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:18.263499Z","iopub.execute_input":"2022-04-17T19:25:18.26379Z","iopub.status.idle":"2022-04-17T19:25:18.274096Z","shell.execute_reply.started":"2022-04-17T19:25:18.263761Z","shell.execute_reply":"2022-04-17T19:25:18.272694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>5 <span style='color:#4285f4'>|</span> Model</b>","metadata":{}},{"cell_type":"markdown","source":"### I am using **VGG16** for transfer learning","metadata":{}},{"cell_type":"code","source":"base_model = VGG16(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), include_top=False, weights='imagenet')\n# Set all layers to non-trainable\nfor layer in base_model.layers:\n    layer.trainable = False\n# Set the last vgg block to trainable\nbase_model.layers[-2].trainable = True\nbase_model.layers[-3].trainable = True\nbase_model.layers[-4].trainable = True\n\nmodel = Sequential()\nmodel.add(Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3)))\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(unique_labels), activation='softmax'))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:20.555409Z","iopub.execute_input":"2022-04-17T19:25:20.556017Z","iopub.status.idle":"2022-04-17T19:25:20.960037Z","shell.execute_reply.started":"2022-04-17T19:25:20.555968Z","shell.execute_reply":"2022-04-17T19:25:20.959033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:23.617918Z","iopub.execute_input":"2022-04-17T19:25:23.618726Z","iopub.status.idle":"2022-04-17T19:25:23.633672Z","shell.execute_reply.started":"2022-04-17T19:25:23.618693Z","shell.execute_reply":"2022-04-17T19:25:23.632404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:25.376459Z","iopub.execute_input":"2022-04-17T19:25:25.376744Z","iopub.status.idle":"2022-04-17T19:25:25.58156Z","shell.execute_reply.started":"2022-04-17T19:25:25.376715Z","shell.execute_reply":"2022-04-17T19:25:25.580256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001),\n             loss='sparse_categorical_crossentropy',\n             metrics=['sparse_categorical_accuracy'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:27.743887Z","iopub.execute_input":"2022-04-17T19:25:27.744727Z","iopub.status.idle":"2022-04-17T19:25:27.761588Z","shell.execute_reply.started":"2022-04-17T19:25:27.744672Z","shell.execute_reply":"2022-04-17T19:25:27.760408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>6 <span style='color:#4285f4'>|</span> Train Model</b>","metadata":{}},{"cell_type":"code","source":"batch_size = 20\nsteps = int(len(train_paths)/batch_size)\nepochs = 4\nhistory = model.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n                    epochs=epochs, steps_per_epoch=steps)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:25:29.444497Z","iopub.execute_input":"2022-04-17T19:25:29.445205Z","iopub.status.idle":"2022-04-17T19:27:08.728116Z","shell.execute_reply.started":"2022-04-17T19:25:29.445172Z","shell.execute_reply":"2022-04-17T19:27:08.727118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.grid(True)\nplt.plot(history.history['sparse_categorical_accuracy'], '.g-', linewidth=2)\nplt.plot(history.history['loss'], '.r-', linewidth=2)\nplt.title('Model Training History')\nplt.xlabel('epoch')\nplt.xticks([x for x in range(epochs)])\nplt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:27:22.157667Z","iopub.execute_input":"2022-04-17T19:27:22.157958Z","iopub.status.idle":"2022-04-17T19:27:22.376095Z","shell.execute_reply.started":"2022-04-17T19:27:22.157928Z","shell.execute_reply":"2022-04-17T19:27:22.375055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>7 <span style='color:#4285f4'>|</span> Evaluate Model with Test Samples</b>","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nsteps = int(len(test_paths)/batch_size)\ny_pred = []\ny_true = []\nfor x,y in tqdm(datagen(test_paths, test_labels, batch_size=batch_size, epochs=1), total=steps):\n    pred = model.predict(x)\n    pred = np.argmax(pred, axis=-1)\n    for i in decode_label(pred):\n        y_pred.append(i)\n    for i in decode_label(y):\n        y_true.append(i)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-17T19:27:24.42188Z","iopub.execute_input":"2022-04-17T19:27:24.42222Z","iopub.status.idle":"2022-04-17T19:27:31.924837Z","shell.execute_reply.started":"2022-04-17T19:27:24.422189Z","shell.execute_reply":"2022-04-17T19:27:31.923776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true, y_pred))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-17T19:27:33.248423Z","iopub.execute_input":"2022-04-17T19:27:33.249214Z","iopub.status.idle":"2022-04-17T19:27:33.276443Z","shell.execute_reply.started":"2022-04-17T19:27:33.249172Z","shell.execute_reply":"2022-04-17T19:27:33.27537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please Upvote this notebook as it encourages me in doing better.\n\n\n![](http://68.media.tumblr.com/e1aed171ded2bd78cc8dc0e73b594eaf/tumblr_o17frv0cdu1u9u459o1_500.gif)","metadata":{}}]}